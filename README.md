# LLM Council ðŸ›ï¸

> **Not an oracle. A deliberation.**

![llmcouncil](header.jpg)

LLM Council is a **deliberative AI engine** that makes model disagreement, confidence, and reasoning visible and measurable. Instead of getting one answer from one model, you get:

- âœ… **Multiple models debate** your question
- âœ… **Anonymized peer review** prevents bias
- âœ… **Disagreement is surfaced**, not hidden
- âœ… **Confidence is calibrated**, not claimed
- âœ… **Full audit trail** of deliberation

## How It Works

```
User Query
    â†“
Stage 1: All models answer independently â†’ [4 responses]
    â†“
Stage 2: Models review each other (anonymized) â†’ [rankings + evaluations]
    â†“
Aggregate Rankings (Bradley-Terry scoring)
    â†“
Stage 3: Chairman synthesizes final answer
    â†“
Output: { responses, evaluations, disagreements, final_answer }
```

## Quick Start

### Prerequisites
- Python 3.10+
- Node.js 18+
- OpenRouter API key ([get one here](https://openrouter.ai/))

### Installation

```bash
# Clone the repo
git clone https://github.com/yourusername/llm-council.git
cd llm-council

# Backend
pip install -e .

# Frontend
cd frontend && npm install && cd ..

# Configure API key
echo "OPENROUTER_API_KEY=sk-or-v1-..." > .env
```

### Run

```bash
# Terminal 1 - Backend
python -m backend.main

# Terminal 2 - Frontend
cd frontend && npm run dev
```

Open http://localhost:5173

## Features

### Core Deliberation
- **Stage 1**: Parallel queries to all council models
- **Stage 2**: Anonymized peer evaluation with structured output
- **Stage 3**: Chairman synthesis with full context

### Algorithmic Improvements
- **Bradley-Terry scoring**: Pairwise preference aggregation
- **Domain expertise weighting**: Math, code, creative, factual
- **Kendall's W**: Inter-rater agreement measurement
- **Claim extraction**: Identify points of agreement/disagreement

### Research-Grade Features
- **Benchmark runner**: Test on MMLU, TruthfulQA, HumanEval
- **Ablation framework**: Compare configurations systematically
- **Calibration tracking**: Measure stated vs actual confidence

### Engineering
- **SQLite storage**: Proper database, not JSON files
- **Circuit breaker**: Fault tolerance for model failures
- **Query caching**: Avoid redundant API calls
- **Docker deployment**: One-command containerized setup

## Configuration

Edit `backend/config.py`:

```python
COUNCIL_MODELS = [
    "google/gemini-2.0-flash-exp:free",
    "meta-llama/llama-3.3-70b-instruct:free",
    "google/gemma-3-27b-it:free",
    "deepseek/deepseek-r1:free",
]

CHAIRMAN_MODEL = "google/gemini-2.0-flash-exp:free"
```

## Deployment (100% FREE) ðŸš€

### Deploy on Render.com (Recommended)

1. **Push to GitHub**
2. **Sign up for Render** (no credit card needed)
3. **New +** â†’ **Blueprint**
4. Connect your repo
5. Add your `OPENROUTER_API_KEY` when asked
6. **Done!** You have a free, live URL.

*Note: The free tier spins down after inactivity (30s cold start).*

### Files Created for Deployment
| File | Purpose |
|------|---------|
| `Dockerfile` | Multi-stage build (Frontend + Backend in one) |
| `render.yaml` | Render configuration |
| `docker-compose.yml` | Local testing |

| Method | Endpoint | Description |
|--------|----------|-------------|
| GET | `/api/conversations` | List conversations |
| POST | `/api/conversations` | Create conversation |
| POST | `/api/conversations/{id}/message` | Send query to council |
| GET | `/api/models` | List available models |
| POST | `/api/estimate` | Get cost estimate |

## Project Structure

```
llm-council/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py          # FastAPI app
â”‚   â”œâ”€â”€ council.py       # Core deliberation
â”‚   â”œâ”€â”€ evaluation.py    # Bradley-Terry scoring
â”‚   â”œâ”€â”€ calibration.py   # Confidence tracking
â”‚   â”œâ”€â”€ claims.py        # Claim extraction
â”‚   â”œâ”€â”€ benchmark.py     # Benchmark runner
â”‚   â”œâ”€â”€ database.py      # SQLite layer
â”‚   â””â”€â”€ resilience.py    # Fault tolerance
â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ components/
â”‚       â”‚   â”œâ”€â”€ EpistemicPanel.jsx
â”‚       â”‚   â”œâ”€â”€ CostEstimator.jsx
â”‚       â”‚   â””â”€â”€ DisagreementExplorer.jsx
â”‚       â””â”€â”€ hooks/
â”‚           â””â”€â”€ useStreaming.js
â””â”€â”€ benchmarks/
```

## Contributing

See [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.

### Good First Issues
- Add dark mode
- Implement response copy button
- Create loading skeletons
- Add keyboard shortcuts

## Tech Stack

- **Backend**: FastAPI, Python 3.10+, async httpx
- **Frontend**: React 19, Vite
- **Storage**: SQLite
- **API**: OpenRouter (unified LLM access)

## License

MIT

---

**Why LLM Council?**

Single models hallucinate. Ensembles catch errors.  
Consensus reveals confidence. Disagreement reveals uncertainty.  
Transparency > black boxes.
